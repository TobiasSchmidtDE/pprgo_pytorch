{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seml\n",
    "import pandas as pd\n",
    "from run_seml import run\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144cf336aab84d63b7d33bc3aa350107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d24bd4a8bee4534ad91597428f469d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/schmidtt/miniconda3/lib/python3.8/site-packages/seml/evaluation.py:48: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  parsed = pd.io.json.json_normalize(parsed, sep='.')\n"
     ]
    }
   ],
   "source": [
    "seml_results = seml.get_results('pprgo_hpt_cora', to_data_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'config.overwrite', 'config.db_collection', 'config.alpha',\n",
       "       'config.attr_normalization', 'config.batch_mult_val',\n",
       "       'config.batch_size', 'config.data_dir', 'config.data_fname',\n",
       "       'config.dropout', 'config.early_stop', 'config.eps', 'config.eval_step',\n",
       "       'config.hidden_size', 'config.inf_fraction', 'config.lr',\n",
       "       'config.max_epochs', 'config.nlayers', 'config.nprop_inference',\n",
       "       'config.ntrain_div_classes', 'config.patience',\n",
       "       'config.ppr_normalization', 'config.run_val', 'config.split_seed',\n",
       "       'config.topk', 'config.weight_decay', 'config.seed',\n",
       "       'result.accuracy_train', 'result.accuracy_val', 'result.accuracy_test',\n",
       "       'result.f1_train', 'result.f1_val', 'result.f1_test',\n",
       "       'result.time_loading', 'result.time_preprocessing',\n",
       "       'result.time_training', 'result.time_inference', 'result.time_logits',\n",
       "       'result.time_propagation', 'result.gpu_memory', 'result.memory',\n",
       "       'result.nepochs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seml_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config.overwrite</th>\n",
       "      <th>config.db_collection</th>\n",
       "      <th>config.alpha</th>\n",
       "      <th>config.attr_normalization</th>\n",
       "      <th>config.batch_mult_val</th>\n",
       "      <th>config.batch_size</th>\n",
       "      <th>config.data_dir</th>\n",
       "      <th>config.data_fname</th>\n",
       "      <th>config.dropout</th>\n",
       "      <th>config.early_stop</th>\n",
       "      <th>...</th>\n",
       "      <th>config.nlayers</th>\n",
       "      <th>config.nprop_inference</th>\n",
       "      <th>config.ntrain_div_classes</th>\n",
       "      <th>config.patience</th>\n",
       "      <th>config.ppr_normalization</th>\n",
       "      <th>config.run_val</th>\n",
       "      <th>config.split_seed</th>\n",
       "      <th>config.topk</th>\n",
       "      <th>config.weight_decay</th>\n",
       "      <th>config.seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>pprgo_hpt_cora</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "      <td>/nfs/shared/data/</td>\n",
       "      <td>cora_ml.npz</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>sym</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>668349245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    config.overwrite config.db_collection  config.alpha  \\\n",
       "64                65       pprgo_hpt_cora          0.25   \n",
       "\n",
       "   config.attr_normalization  config.batch_mult_val  config.batch_size  \\\n",
       "64                      None                      4                512   \n",
       "\n",
       "      config.data_dir config.data_fname  config.dropout  config.early_stop  \\\n",
       "64  /nfs/shared/data/       cora_ml.npz             0.1              False   \n",
       "\n",
       "    ...  config.nlayers  config.nprop_inference  config.ntrain_div_classes  \\\n",
       "64  ...               3                       2                         20   \n",
       "\n",
       "    config.patience  config.ppr_normalization  config.run_val  \\\n",
       "64               50                       sym           False   \n",
       "\n",
       "    config.split_seed  config.topk  config.weight_decay  config.seed  \n",
       "64                  0           64               0.0001    668349245  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_keys = [c for c in seml_results.columns if \"config\" in c]\n",
    "seml_results[seml_results[\"result.accuracy_test\"] == seml_results[\"result.accuracy_test\"].max()][config_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.25,\n",
       " 'attr_normalization': None,\n",
       " 'batch_mult_val': 4,\n",
       " 'batch_size': 512,\n",
       " 'data_dir': '/nfs/shared/data/',\n",
       " 'data_fname': 'cora_ml.npz',\n",
       " 'dropout': 0.1,\n",
       " 'early_stop': False,\n",
       " 'eps': 0.01,\n",
       " 'eval_step': 1,\n",
       " 'hidden_size': 64,\n",
       " 'inf_fraction': 1.0,\n",
       " 'lr': 0.005,\n",
       " 'max_epochs': 200,\n",
       " 'nlayers': 3,\n",
       " 'nprop_inference': 2,\n",
       " 'ntrain_div_classes': 20,\n",
       " 'patience': 50,\n",
       " 'ppr_normalization': 'sym',\n",
       " 'run_val': False,\n",
       " 'split_seed': 0,\n",
       " 'topk': 32,\n",
       " 'weight_decay': 0.0001,\n",
       " 'aggr': 'sum'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 64\n",
    "config = {k.replace(\"config.\", \"\"):v for k, v in seml_results.iloc[24][config_keys].items()}\n",
    "config.pop(\"overwrite\")\n",
    "config.pop(\"db_collection\")\n",
    "config.pop(\"seed\")\n",
    "config[\"batch_size\"] = int(config[\"batch_size\"])\n",
    "config[\"aggr\"] = \"sum\"\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 14:58:25 (INFO): Loading done.\n",
      "2020-12-21 14:58:25 (INFO): Preprocessing done.\n",
      "2020-12-21 14:58:25 (INFO): Epoch 0, step 1: train 0.01390\n",
      "2020-12-21 14:58:25 (INFO): Epoch 1, step 2: train 0.01389\n",
      "2020-12-21 14:58:25 (INFO): Epoch 2, step 3: train 0.01387\n",
      "2020-12-21 14:58:25 (INFO): Epoch 3, step 4: train 0.01384\n",
      "2020-12-21 14:58:25 (INFO): Epoch 4, step 5: train 0.01380\n",
      "2020-12-21 14:58:25 (INFO): Epoch 5, step 6: train 0.01374\n",
      "2020-12-21 14:58:25 (INFO): Epoch 6, step 7: train 0.01367\n",
      "2020-12-21 14:58:25 (INFO): Epoch 7, step 8: train 0.01359\n",
      "2020-12-21 14:58:25 (INFO): Epoch 8, step 9: train 0.01349\n",
      "2020-12-21 14:58:25 (INFO): Epoch 9, step 10: train 0.01337\n",
      "2020-12-21 14:58:25 (INFO): Epoch 10, step 11: train 0.01324\n",
      "2020-12-21 14:58:25 (INFO): Epoch 11, step 12: train 0.01309\n",
      "2020-12-21 14:58:25 (INFO): Epoch 12, step 13: train 0.01293\n",
      "2020-12-21 14:58:25 (INFO): Epoch 13, step 14: train 0.01277\n",
      "2020-12-21 14:58:25 (INFO): Epoch 14, step 15: train 0.01260\n",
      "2020-12-21 14:58:25 (INFO): Epoch 15, step 16: train 0.01243\n",
      "2020-12-21 14:58:25 (INFO): Epoch 16, step 17: train 0.01225\n",
      "2020-12-21 14:58:25 (INFO): Epoch 17, step 18: train 0.01207\n",
      "2020-12-21 14:58:25 (INFO): Epoch 18, step 19: train 0.01189\n",
      "2020-12-21 14:58:25 (INFO): Epoch 19, step 20: train 0.01170\n",
      "2020-12-21 14:58:25 (INFO): Epoch 20, step 21: train 0.01150\n",
      "2020-12-21 14:58:25 (INFO): Epoch 21, step 22: train 0.01131\n",
      "2020-12-21 14:58:25 (INFO): Epoch 22, step 23: train 0.01110\n",
      "2020-12-21 14:58:25 (INFO): Epoch 23, step 24: train 0.01091\n",
      "2020-12-21 14:58:25 (INFO): Epoch 24, step 25: train 0.01071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "<class 'int'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 14:58:25 (INFO): Epoch 25, step 26: train 0.01051\n",
      "2020-12-21 14:58:25 (INFO): Epoch 26, step 27: train 0.01030\n",
      "2020-12-21 14:58:25 (INFO): Epoch 27, step 28: train 0.01010\n",
      "2020-12-21 14:58:25 (INFO): Epoch 28, step 29: train 0.00990\n",
      "2020-12-21 14:58:25 (INFO): Epoch 29, step 30: train 0.00970\n",
      "2020-12-21 14:58:25 (INFO): Epoch 30, step 31: train 0.00950\n",
      "2020-12-21 14:58:25 (INFO): Epoch 31, step 32: train 0.00930\n",
      "2020-12-21 14:58:25 (INFO): Epoch 32, step 33: train 0.00910\n",
      "2020-12-21 14:58:25 (INFO): Epoch 33, step 34: train 0.00891\n",
      "2020-12-21 14:58:25 (INFO): Epoch 34, step 35: train 0.00872\n",
      "2020-12-21 14:58:25 (INFO): Epoch 35, step 36: train 0.00853\n",
      "2020-12-21 14:58:25 (INFO): Epoch 36, step 37: train 0.00834\n",
      "2020-12-21 14:58:25 (INFO): Epoch 37, step 38: train 0.00816\n",
      "2020-12-21 14:58:25 (INFO): Epoch 38, step 39: train 0.00798\n",
      "2020-12-21 14:58:25 (INFO): Epoch 39, step 40: train 0.00780\n",
      "2020-12-21 14:58:25 (INFO): Epoch 40, step 41: train 0.00763\n",
      "2020-12-21 14:58:25 (INFO): Epoch 41, step 42: train 0.00746\n",
      "2020-12-21 14:58:25 (INFO): Epoch 42, step 43: train 0.00730\n",
      "2020-12-21 14:58:25 (INFO): Epoch 43, step 44: train 0.00714\n",
      "2020-12-21 14:58:25 (INFO): Epoch 44, step 45: train 0.00699\n",
      "2020-12-21 14:58:25 (INFO): Epoch 45, step 46: train 0.00685\n",
      "2020-12-21 14:58:25 (INFO): Epoch 46, step 47: train 0.00671\n",
      "2020-12-21 14:58:25 (INFO): Epoch 47, step 48: train 0.00657\n",
      "2020-12-21 14:58:25 (INFO): Epoch 48, step 49: train 0.00644\n",
      "2020-12-21 14:58:25 (INFO): Epoch 49, step 50: train 0.00632\n",
      "2020-12-21 14:58:25 (INFO): Epoch 50, step 51: train 0.00620\n",
      "2020-12-21 14:58:25 (INFO): Epoch 51, step 52: train 0.00608\n",
      "2020-12-21 14:58:25 (INFO): Epoch 52, step 53: train 0.00597\n",
      "2020-12-21 14:58:25 (INFO): Epoch 53, step 54: train 0.00586\n",
      "2020-12-21 14:58:25 (INFO): Epoch 54, step 55: train 0.00575\n",
      "2020-12-21 14:58:25 (INFO): Epoch 55, step 56: train 0.00565\n",
      "2020-12-21 14:58:25 (INFO): Epoch 56, step 57: train 0.00555\n",
      "2020-12-21 14:58:25 (INFO): Epoch 57, step 58: train 0.00546\n",
      "2020-12-21 14:58:25 (INFO): Epoch 58, step 59: train 0.00537\n",
      "2020-12-21 14:58:25 (INFO): Epoch 59, step 60: train 0.00528\n",
      "2020-12-21 14:58:25 (INFO): Epoch 60, step 61: train 0.00519\n",
      "2020-12-21 14:58:25 (INFO): Epoch 61, step 62: train 0.00511\n",
      "2020-12-21 14:58:25 (INFO): Epoch 62, step 63: train 0.00503\n",
      "2020-12-21 14:58:25 (INFO): Epoch 63, step 64: train 0.00495\n",
      "2020-12-21 14:58:25 (INFO): Epoch 64, step 65: train 0.00488\n",
      "2020-12-21 14:58:25 (INFO): Epoch 65, step 66: train 0.00480\n",
      "2020-12-21 14:58:25 (INFO): Epoch 66, step 67: train 0.00473\n",
      "2020-12-21 14:58:25 (INFO): Epoch 67, step 68: train 0.00466\n",
      "2020-12-21 14:58:25 (INFO): Epoch 68, step 69: train 0.00460\n",
      "2020-12-21 14:58:25 (INFO): Epoch 69, step 70: train 0.00453\n",
      "2020-12-21 14:58:25 (INFO): Epoch 70, step 71: train 0.00447\n",
      "2020-12-21 14:58:25 (INFO): Epoch 71, step 72: train 0.00441\n",
      "2020-12-21 14:58:25 (INFO): Epoch 72, step 73: train 0.00435\n",
      "2020-12-21 14:58:25 (INFO): Epoch 73, step 74: train 0.00429\n",
      "2020-12-21 14:58:25 (INFO): Epoch 74, step 75: train 0.00423\n",
      "2020-12-21 14:58:25 (INFO): Epoch 75, step 76: train 0.00418\n",
      "2020-12-21 14:58:25 (INFO): Epoch 76, step 77: train 0.00412\n",
      "2020-12-21 14:58:25 (INFO): Epoch 77, step 78: train 0.00407\n",
      "2020-12-21 14:58:25 (INFO): Epoch 78, step 79: train 0.00402\n",
      "2020-12-21 14:58:25 (INFO): Epoch 79, step 80: train 0.00397\n",
      "2020-12-21 14:58:25 (INFO): Epoch 80, step 81: train 0.00392\n",
      "2020-12-21 14:58:25 (INFO): Epoch 81, step 82: train 0.00387\n",
      "2020-12-21 14:58:25 (INFO): Epoch 82, step 83: train 0.00383\n",
      "2020-12-21 14:58:25 (INFO): Epoch 83, step 84: train 0.00378\n",
      "2020-12-21 14:58:25 (INFO): Epoch 84, step 85: train 0.00374\n",
      "2020-12-21 14:58:25 (INFO): Epoch 85, step 86: train 0.00370\n",
      "2020-12-21 14:58:25 (INFO): Epoch 86, step 87: train 0.00365\n",
      "2020-12-21 14:58:25 (INFO): Epoch 87, step 88: train 0.00361\n",
      "2020-12-21 14:58:25 (INFO): Epoch 88, step 89: train 0.00357\n",
      "2020-12-21 14:58:25 (INFO): Epoch 89, step 90: train 0.00353\n",
      "2020-12-21 14:58:25 (INFO): Epoch 90, step 91: train 0.00350\n",
      "2020-12-21 14:58:25 (INFO): Epoch 91, step 92: train 0.00346\n",
      "2020-12-21 14:58:25 (INFO): Epoch 92, step 93: train 0.00342\n",
      "2020-12-21 14:58:25 (INFO): Epoch 93, step 94: train 0.00339\n",
      "2020-12-21 14:58:25 (INFO): Epoch 94, step 95: train 0.00335\n",
      "2020-12-21 14:58:25 (INFO): Epoch 95, step 96: train 0.00332\n",
      "2020-12-21 14:58:25 (INFO): Epoch 96, step 97: train 0.00328\n",
      "2020-12-21 14:58:25 (INFO): Epoch 97, step 98: train 0.00325\n",
      "2020-12-21 14:58:25 (INFO): Epoch 98, step 99: train 0.00322\n",
      "2020-12-21 14:58:25 (INFO): Epoch 99, step 100: train 0.00319\n",
      "2020-12-21 14:58:25 (INFO): Epoch 100, step 101: train 0.00315\n",
      "2020-12-21 14:58:25 (INFO): Epoch 101, step 102: train 0.00312\n",
      "2020-12-21 14:58:25 (INFO): Epoch 102, step 103: train 0.00309\n",
      "2020-12-21 14:58:25 (INFO): Epoch 103, step 104: train 0.00307\n",
      "2020-12-21 14:58:25 (INFO): Epoch 104, step 105: train 0.00304\n",
      "2020-12-21 14:58:25 (INFO): Epoch 105, step 106: train 0.00301\n",
      "2020-12-21 14:58:25 (INFO): Epoch 106, step 107: train 0.00298\n",
      "2020-12-21 14:58:25 (INFO): Epoch 107, step 108: train 0.00295\n",
      "2020-12-21 14:58:25 (INFO): Epoch 108, step 109: train 0.00293\n",
      "2020-12-21 14:58:25 (INFO): Epoch 109, step 110: train 0.00290\n",
      "2020-12-21 14:58:25 (INFO): Epoch 110, step 111: train 0.00288\n",
      "2020-12-21 14:58:25 (INFO): Epoch 111, step 112: train 0.00285\n",
      "2020-12-21 14:58:25 (INFO): Epoch 112, step 113: train 0.00283\n",
      "2020-12-21 14:58:25 (INFO): Epoch 113, step 114: train 0.00280\n",
      "2020-12-21 14:58:25 (INFO): Epoch 114, step 115: train 0.00278\n",
      "2020-12-21 14:58:25 (INFO): Epoch 115, step 116: train 0.00275\n",
      "2020-12-21 14:58:25 (INFO): Epoch 116, step 117: train 0.00273\n",
      "2020-12-21 14:58:25 (INFO): Epoch 117, step 118: train 0.00271\n",
      "2020-12-21 14:58:25 (INFO): Epoch 118, step 119: train 0.00269\n",
      "2020-12-21 14:58:25 (INFO): Epoch 119, step 120: train 0.00266\n",
      "2020-12-21 14:58:25 (INFO): Epoch 120, step 121: train 0.00264\n",
      "2020-12-21 14:58:25 (INFO): Epoch 121, step 122: train 0.00262\n",
      "2020-12-21 14:58:25 (INFO): Epoch 122, step 123: train 0.00260\n",
      "2020-12-21 14:58:25 (INFO): Epoch 123, step 124: train 0.00258\n",
      "2020-12-21 14:58:25 (INFO): Epoch 124, step 125: train 0.00256\n",
      "2020-12-21 14:58:25 (INFO): Epoch 125, step 126: train 0.00254\n",
      "2020-12-21 14:58:25 (INFO): Epoch 126, step 127: train 0.00252\n",
      "2020-12-21 14:58:25 (INFO): Epoch 127, step 128: train 0.00250\n",
      "2020-12-21 14:58:25 (INFO): Epoch 128, step 129: train 0.00248\n",
      "2020-12-21 14:58:25 (INFO): Epoch 129, step 130: train 0.00246\n",
      "2020-12-21 14:58:25 (INFO): Epoch 130, step 131: train 0.00245\n",
      "2020-12-21 14:58:25 (INFO): Epoch 131, step 132: train 0.00243\n",
      "2020-12-21 14:58:25 (INFO): Epoch 132, step 133: train 0.00241\n",
      "2020-12-21 14:58:25 (INFO): Epoch 133, step 134: train 0.00239\n",
      "2020-12-21 14:58:25 (INFO): Epoch 134, step 135: train 0.00237\n",
      "2020-12-21 14:58:25 (INFO): Epoch 135, step 136: train 0.00236\n",
      "2020-12-21 14:58:25 (INFO): Epoch 136, step 137: train 0.00234\n",
      "2020-12-21 14:58:25 (INFO): Epoch 137, step 138: train 0.00232\n",
      "2020-12-21 14:58:25 (INFO): Epoch 138, step 139: train 0.00231\n",
      "2020-12-21 14:58:25 (INFO): Epoch 139, step 140: train 0.00229\n",
      "2020-12-21 14:58:25 (INFO): Epoch 140, step 141: train 0.00228\n",
      "2020-12-21 14:58:25 (INFO): Epoch 141, step 142: train 0.00226\n",
      "2020-12-21 14:58:25 (INFO): Epoch 142, step 143: train 0.00224\n",
      "2020-12-21 14:58:25 (INFO): Epoch 143, step 144: train 0.00223\n",
      "2020-12-21 14:58:25 (INFO): Epoch 144, step 145: train 0.00221\n",
      "2020-12-21 14:58:25 (INFO): Epoch 145, step 146: train 0.00220\n",
      "2020-12-21 14:58:25 (INFO): Epoch 146, step 147: train 0.00218\n",
      "2020-12-21 14:58:25 (INFO): Epoch 147, step 148: train 0.00217\n",
      "2020-12-21 14:58:25 (INFO): Epoch 148, step 149: train 0.00216\n",
      "2020-12-21 14:58:25 (INFO): Epoch 149, step 150: train 0.00214\n",
      "2020-12-21 14:58:25 (INFO): Epoch 150, step 151: train 0.00213\n",
      "2020-12-21 14:58:25 (INFO): Epoch 151, step 152: train 0.00211\n",
      "2020-12-21 14:58:25 (INFO): Epoch 152, step 153: train 0.00210\n",
      "2020-12-21 14:58:25 (INFO): Epoch 153, step 154: train 0.00209\n",
      "2020-12-21 14:58:25 (INFO): Epoch 154, step 155: train 0.00207\n",
      "2020-12-21 14:58:25 (INFO): Epoch 155, step 156: train 0.00206\n",
      "2020-12-21 14:58:25 (INFO): Epoch 156, step 157: train 0.00205\n",
      "2020-12-21 14:58:25 (INFO): Epoch 157, step 158: train 0.00204\n",
      "2020-12-21 14:58:25 (INFO): Epoch 158, step 159: train 0.00202\n",
      "2020-12-21 14:58:25 (INFO): Epoch 159, step 160: train 0.00201\n",
      "2020-12-21 14:58:25 (INFO): Epoch 160, step 161: train 0.00200\n",
      "2020-12-21 14:58:25 (INFO): Epoch 161, step 162: train 0.00199\n",
      "2020-12-21 14:58:25 (INFO): Epoch 162, step 163: train 0.00198\n",
      "2020-12-21 14:58:25 (INFO): Epoch 163, step 164: train 0.00196\n",
      "2020-12-21 14:58:25 (INFO): Epoch 164, step 165: train 0.00195\n",
      "2020-12-21 14:58:25 (INFO): Epoch 165, step 166: train 0.00194\n",
      "2020-12-21 14:58:25 (INFO): Epoch 166, step 167: train 0.00193\n",
      "2020-12-21 14:58:25 (INFO): Epoch 167, step 168: train 0.00192\n",
      "2020-12-21 14:58:25 (INFO): Epoch 168, step 169: train 0.00191\n",
      "2020-12-21 14:58:25 (INFO): Epoch 169, step 170: train 0.00190\n",
      "2020-12-21 14:58:25 (INFO): Epoch 170, step 171: train 0.00188\n",
      "2020-12-21 14:58:25 (INFO): Epoch 171, step 172: train 0.00187\n",
      "2020-12-21 14:58:26 (INFO): Epoch 172, step 173: train 0.00186\n",
      "2020-12-21 14:58:26 (INFO): Epoch 173, step 174: train 0.00185\n",
      "2020-12-21 14:58:26 (INFO): Epoch 174, step 175: train 0.00184\n",
      "2020-12-21 14:58:26 (INFO): Epoch 175, step 176: train 0.00183\n",
      "2020-12-21 14:58:26 (INFO): Epoch 176, step 177: train 0.00182\n",
      "2020-12-21 14:58:26 (INFO): Epoch 177, step 178: train 0.00181\n",
      "2020-12-21 14:58:26 (INFO): Epoch 178, step 179: train 0.00180\n",
      "2020-12-21 14:58:26 (INFO): Epoch 179, step 180: train 0.00179\n",
      "2020-12-21 14:58:26 (INFO): Epoch 180, step 181: train 0.00178\n",
      "2020-12-21 14:58:26 (INFO): Epoch 181, step 182: train 0.00177\n",
      "2020-12-21 14:58:26 (INFO): Epoch 182, step 183: train 0.00176\n",
      "2020-12-21 14:58:26 (INFO): Epoch 183, step 184: train 0.00175\n",
      "2020-12-21 14:58:26 (INFO): Epoch 184, step 185: train 0.00175\n",
      "2020-12-21 14:58:26 (INFO): Epoch 185, step 186: train 0.00174\n",
      "2020-12-21 14:58:26 (INFO): Epoch 186, step 187: train 0.00173\n",
      "2020-12-21 14:58:26 (INFO): Epoch 187, step 188: train 0.00172\n",
      "2020-12-21 14:58:26 (INFO): Epoch 188, step 189: train 0.00171\n",
      "2020-12-21 14:58:26 (INFO): Epoch 189, step 190: train 0.00170\n",
      "2020-12-21 14:58:26 (INFO): Epoch 190, step 191: train 0.00169\n",
      "2020-12-21 14:58:26 (INFO): Epoch 191, step 192: train 0.00168\n",
      "2020-12-21 14:58:26 (INFO): Epoch 192, step 193: train 0.00167\n",
      "2020-12-21 14:58:26 (INFO): Epoch 193, step 194: train 0.00167\n",
      "2020-12-21 14:58:26 (INFO): Epoch 194, step 195: train 0.00166\n",
      "2020-12-21 14:58:26 (INFO): Epoch 195, step 196: train 0.00165\n",
      "2020-12-21 14:58:26 (INFO): Epoch 196, step 197: train 0.00164\n",
      "2020-12-21 14:58:26 (INFO): Epoch 197, step 198: train 0.00163\n",
      "2020-12-21 14:58:26 (INFO): Epoch 198, step 199: train 0.00163\n",
      "2020-12-21 14:58:26 (INFO): Epoch 199, step 200: train 0.00162\n",
      "2020-12-21 14:58:26 (INFO): Training done.\n",
      "2020-12-21 14:58:26 (INFO): Inference done.\n"
     ]
    }
   ],
   "source": [
    "results = run(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 100.0,\n",
       " 'accuracy_val': 82.71428571428572,\n",
       " 'accuracy_test': 81.65354330708662,\n",
       " 'f1_train': 1.0,\n",
       " 'f1_val': 0.808732503433484,\n",
       " 'f1_test': 0.8039586412758616,\n",
       " 'time_loading': 0.021263599395751953,\n",
       " 'time_preprocessing': 0.0038497447967529297,\n",
       " 'time_training': 1.0438570976257324,\n",
       " 'time_inference': 0.006062984466552734,\n",
       " 'time_logits': 0.004880666732788086,\n",
       " 'time_propagation': 0.0011315345764160156,\n",
       " 'gpu_memory': 15502336,\n",
       " 'memory': 2118467584,\n",
       " 'nepochs': 200}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
